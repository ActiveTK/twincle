以下、\*\*この実装で“効きそうなボトルネック”\*\*と、そこからの\*\*改善アイディア\*\*、そしてご質問の \*\*「10^17 以上で f64 の誤差」\*\*と \*\*Kahan 適用可否 / GPU 選び\*\*をまとめます（実測なしの静的解析ですが、かなり典型的な詰まりどころが見えます）。



---



\## 1) ボトルネック候補（どこが遅くなりやすいか）



\### A. `sieve\_wheel\_primes` の `atomicOr` が支配的になりやすい



```cpp

atomicOr(\&comp\_p\_words\[bit\_word(idx)], bit\_mask(idx));

atomicOr(\&comp\_p2\_words\[bit\_word(idx)], bit\_mask(idx));

```



\* \*\*小さい素数 q\*\*ほどマーキング回数が多く、同じ/近い word への更新が集中しやすい

&nbsp; → L2 での \*\*atomic 競合/直列化\*\*が起きやすいです。

\* さらに `idx = (kk - k\_low) \* R + ridx` のレイアウトだと、固定 `ridx` で `kk` を増やすと `idx` が \*\*R ストライド\*\*で飛びます。R が数千級だと \*\*キャッシュ局所性が悪く、atomic 先が散る\*\*＝帯域効率が落ちます。



\### B. “(prime, residue) 全ペア”にスレッドを割り当てる方式のオーバーヘッド



```cpp

total\_pairs = prime\_count \* R;

for (pair = tid; pair < total\_pairs; pair += stride) { ... }

```



\* これは \*\*負荷分散は良い\*\*一方で、`q` が大きい領域では各ペアがほぼ 0〜1 回しか mark しないのに、

&nbsp; 毎回「mod 計算・初期位置計算・whileでq²チェック」などの\*\*固定費\*\*を払います。

\* `limit` を上げるほど `prime\_count` が増えるので、\*\*固定費の総量が爆発\*\*します。



> 特に `N=1e17` だと `sqrt(N)≈3.16e8` までの素数が必要で、素数数は \*\*約1600万\*\*規模。

> `prime\_count \* R` は現実的に回りません（性能以前に総演算量が破綻します）。



\### C. セグメントごとの `stream.synchronize()` がパイプラインを殺す



Rust 側で毎セグメント



```rust

stream.synchronize()?;

d\_sum.copy\_to(\&mut h\_sum)?;

d\_cnt.copy\_to(\&mut h\_cnt)?;

```



\* これで \*\*GPU計算とCPU処理/次セグ準備が完全直列\*\*になります。

\* 小さめの `segment\_k` にするとこの同期回数が増えて、\*\*カーネル起動＋同期＋転送の固定費\*\*が効いてきます。



\### D. `twin\_sum\_wheel` の `atomicAdd(d\_sum)` が精度・性能の両面でノイズ



```cpp

atomicAdd(d\_sum, local\_sum);

```



\* 性能面：ブロック数が多いと atomicAdd が詰まります（ただし sieve の atomicOr よりは軽いことも多い）。

\* 精度面：加算順が非決定的で、\*\*丸め誤差が再現性なく増える\*\*原因になります。



---



\## 2) 改善アイディア（効果が出やすい順に）



\### ① bitset のメモリ配置を変える（局所性を作る）



今は `idx=(k-k\_low)\*R + ridx` なので、\*\*k 方向に連続、residue が内側\*\*です。



ふるいのマーキングは「固定 residue で k を q 刻み」なので、\*\*residue ごとの k 列が連続\*\*になっている方が有利です。

つまり \*\*`idx = ridx\*k\_count + (k-k\_low)`\*\* にすると：



\* 固定 `ridx` のマーキングが \*\*ほぼ連続アクセス\*\*になる

\* word のキャッシュ効率が上がり、atomic の散り方が改善しやすい

\* `twin\_sum` 側も「ridx ループ＋word走査」で素直に読める（読みやすい帯域型になる）



これは「実装変更はそこそこ」ですが、\*\*当たりやすい改善\*\*です。



---



\### ② 小さい素数だけ別扱いにして atomicOr を減らす（2段階 sieve）



典型手法です：



\* \*\*小さい q（例：q ≤ 2^15 とか）\*\*は mark 回数が多く競合しやすい

&nbsp; → \*\*ブロックが“自分の担当タイル”を shared / レジスタで更新して最後にまとめて書く\*\*（atomic なし or 激減）

\* \*\*大きい q\*\*は mark 回数が少ないので atomic 競合が相対的に減る

&nbsp; → 現方式（atomicOr）でも許容、あるいは別の sparse 手法へ



GPU segmented sieve の王道で、\*\*sieve の主ボトルネック（atomic 競合）を直撃\*\*できます。



---



\### ③ “全 prime×residue ペア列挙”をやめて、素数側を分割して処理する



現状は巨大な `prime\_count\*R` を舐めます。これを抑える方向として：



\* q を \*\*レンジ分割\*\*し、レンジごとに専用カーネル（または同一カーネル内で分岐）



&nbsp; \* 小 q：heavy marking → いまの「分散」戦略が効く

&nbsp; \* 中 q：tile方式

&nbsp; \* 大 q：各ペアの mark が 0/1 に近い → ペア列挙の固定費が無駄になりやすいので、別のやり方を検討



大 q は「次に打つべき位置（次回の k）」を保持する \*\*bucket/スケジューラ方式\*\*がCPUでは定番ですが、

GPUで prime×residue 全状態を持つのはメモリ的に厳しいので、\*\*“大 q はそもそも別戦略”\*\*が必要になります。



---



\### ④ セグメントをパイプライン化（同期を消して転送を隠す）



いまは



\* clear → sieve → twin → `synchronize` → copy\_to → 次セグ



なので、以下が効きます：



\* \*\*ダブルバッファ\*\*（comp\_p/comp\_p2 と sum/cnt を2組）にして

&nbsp; セグ i を回しながらセグ i-1 の結果を転送・集計

\* `copy\_to` を \*\*非同期 memcpy\*\*（可能なら）＋ CUDA event で待つ

\* 可能なら \*\*CUDA Graph\*\* で（clear+sieve+twin）の起動オーバーヘッドも削る



これは「純粋に固定費を落とす」ので、`segment\_k` を小さくしたいときほど効きます。



---



\### ⑤ `twin\_sum` の atomicAdd をやめる（精度も上がる）



\*\*性能\*\*と\*\*精度\*\*の両方に効く手がこれです：



\* `twin\_sum\_wheel` で \*\*ブロックごとの部分和\*\*を `block\_sums\[gridDim.x]` に書くだけにする（atomicなし）

\* ホストにコピーして、CPU側で \*\*Kahan\*\*（あるいは `f128` 相当の多倍長）で合計



転送量は `gridDim.x \* (8+8)` バイト程度（sum+count）なので、たとえば 262,144 ブロックでも約 4MB/セグ。

PCIeでも十分扱える範囲のことが多く、atomicの詰まりと非決定順序を消せます。



---



\## 3) 10^17 以上で f64 は誤差が蓄積する？（結論：はい、普通に起きます）



\### 重要ポイント：\*\*和のスケールが O(1) なのに、加える項が 1e-17 級\*\*



Brun 部分和は最終的に ~1.9 付近に収束する定数です。

一方、p が 1e17 だと `1/p ≈ 1e-17` です。



\* f64 の機械イプシロンは約 `2^-52 ≈ 2.22e-16`

\* 和が ~1〜2 付近だと、\*\*1回の加算で反映できる最小刻み\*\*がだいたい `数e-16` 程度



つまり \*\*1e-17 の項は“足しても消える”\*\*状況に入り、単純加算だと後半の寄与を落とし始めます。



さらにこの実装は



\* スレッド内加算 → warp shuffle 加算 → block 加算 → `atomicAdd`

&nbsp; と \*\*加算順が強く非決定\*\*になり、誤差が増えやすい構造です。



---



\## 4) Kahan を適用できるか？（可能。ただし“どこに入れるか”が大事）



\### (A) GPUスレッド内に Kahan（簡単・効果は限定）



`local\_sum` を Kahan (sum,c) にするのは実装できます。

ただし、その後の warp/block reduction や atomicAdd でまた誤差が入るので、\*\*効果は“あるが限定的”\*\*になりがちです。



\### (B) おすすめ：\*\*ブロック部分和を吐いてCPUでKahan\*\*



上で挙げた「atomicAdd をやめる」案が、Kahan の効果を最大化します。



\* GPU：ブロックごとに `double sum` と `u64 count` を配列へ

\* CPU：全ブロックの sum を Kahan で足す（さらにセグメント間も Kahan）



これなら



\* 加算順を制御できる（少なくとも固定順で再現性が出る）

\* `atomicAdd` の非決定性が消える

\* Kahan がちゃんと効く



\### (C) さらに上：GPUで double-double（hi+lo）で部分和



もし 1e17 以上を本気でやるなら、ブロック部分和を `double2`（hi,lo）で持って CPU で合成、も検討価値があります。

ただし計算コストは上がります。



---



\## 5) 「double計算なら H100/A100 が圧倒的に有利？」（半分YES）



\### YES な点



\* A100/H100 は \*\*FP64 throughput が大きい\*\*（consumer GPU は FP64 が極端に弱いことが多い）

\* `twin\_sum` は `1.0/(double)p` を大量に実行するので、ここは \*\*FP64 が効く\*\*



\### ただし注意：このコードは “FP64だけ” が支配ではない



\* `sieve\_wheel\_primes` はほぼ \*\*整数演算＋atomicOr＋メモリ帯域/競合\*\*が支配

\* ここは FP64 性能より \*\*メモリ階層・L2・atomic性能\*\*やアクセスパターン最適化の影響が大きいです



なので結論は：



\* \*\*現状のまま\*\*なら「`twin\_sum` はH100/A100が強い」「sieveは別要因が大きい」

\* もし `twin\_sum` の atomicAdd をやめて CPU 合算に寄せるなどで FP64 負荷を下げると、\*\*GPU間の差は縮む\*\*可能性があります



